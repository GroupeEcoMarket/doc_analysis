"""
API routes for document analysis
"""

from fastapi import APIRouter, UploadFile, File, HTTPException, BackgroundTasks, Depends
from fastapi.responses import JSONResponse
from typing import Optional, Dict, Any, List, Tuple, Annotated
from pydantic import BaseModel, Field
import os
from pathlib import Path
import numpy as np
import cv2
import time
from concurrent.futures import ProcessPoolExecutor

from src.services.processing_service import ProcessingService
from src.services.task_manager import get_task_manager, TaskStatus
from src.api.dependencies import (
    get_preprocessing_normalizer,
    get_geometry_normalizer,
    get_app_config,
    get_feature_extractor,
    get_document_classifier
)
from src.pipeline.preprocessing import PreprocessingNormalizer
from src.pipeline.geometry import GeometryNormalizer
from src.pipeline.features import FeatureExtractor
from src.classification.classifier_service import DocumentClassifier
from src.utils.logger import get_logger, get_request_id
from src.utils.exceptions import (
    GeometryError, 
    PreprocessingError, 
    ModelLoadingError, 
    ImageProcessingError,
    PipelineError
)
from src.utils.pdf_handler import is_pdf

logger = get_logger(__name__)

router = APIRouter()

# Initialize task manager (singleton)
task_manager = get_task_manager()


# ==========================================
# Multiprocessing Worker Functions
# ==========================================

# Dictionnaire global pour stocker les dépendances initialisées dans chaque worker
worker_dependencies = {}


def init_api_worker():
    """
    Initialise les dépendances (modèles lourds) une seule fois par processus worker.
    """
    global worker_dependencies
    if 'feature_extractor' not in worker_dependencies:
        print(f"Initialisation des modèles pour le worker PID: {os.getpid()}")
        # On utilise les fonctions de dépendances pour recréer les objets
        config = get_app_config()
        worker_dependencies['feature_extractor'] = get_feature_extractor(config)
        try:
            worker_dependencies['document_classifier'] = get_document_classifier(config)
        except ValueError:
            # Gérer le cas où la classification est désactivée
            worker_dependencies['document_classifier'] = None
    else:
        print(f"Modèles déjà initialisés pour le worker PID: {os.getpid()}")


def process_page_worker(page_tuple: Tuple[int, np.ndarray]) -> Tuple[int, Dict[str, Any]]:
    """
    Fonction exécutée par chaque worker pour traiter une seule page.
    Utilise les modèles initialisés dans worker_dependencies.
    """
    page_index, image_np = page_tuple
    
    feature_extractor = worker_dependencies.get('feature_extractor')
    document_classifier = worker_dependencies.get('document_classifier')
    
    if not feature_extractor or not document_classifier:
        # Si les modèles ne sont pas chargés, on retourne une erreur
        return page_index, {
            'document_type': None,
            'confidence': 0.0,
            'error': "Classifier non disponible dans le worker."
        }
        
    ocr_lines = feature_extractor.extract_ocr(image_np)
    ocr_data = {'ocr_lines': ocr_lines}
    classification_result = document_classifier.predict(ocr_data)
    
    return page_index, classification_result


# ==========================================
# Pydantic Response Models
# ==========================================

class OutputFiles(BaseModel):
    """Output file paths generated by the pipeline"""
    transformed: str = Field(..., description="Path to the transformed/processed image")
    original: Optional[str] = Field(None, description="Path to the original image (if saved)")
    transform_file: str = Field(..., description="Path to the JSON file containing applied transformations")
    qa_file: str = Field(..., description="Path to the JSON file containing QA flags")


class Metadata(BaseModel):
    """Processing metadata and applied transformations"""
    crop_applied: bool = Field(..., description="Whether intelligent cropping was applied")
    deskew_applied: bool = Field(..., description="Whether angle correction (deskew) was applied")
    rotation_applied: bool = Field(..., description="Whether orientation correction was applied")
    orientation_angle: float = Field(..., description="Detected orientation angle in degrees")
    capture_type: str = Field(..., description="Detected capture type: 'SCAN' or 'PHOTO'")
    processing_time: float = Field(..., description="Total processing time in seconds")


class TempDirs(BaseModel):
    """Temporary directories used during processing"""
    input: str = Field(..., description="Temporary directory for input files")
    output: str = Field(..., description="Temporary directory for output files")
    preprocessing: str = Field(..., description="Temporary directory for preprocessing files")


class PipelineStages(BaseModel):
    """Status of each pipeline stage"""
    preprocessing: str = Field(..., description="Status of preprocessing stage")
    geometry: str = Field(..., description="Status of geometry normalization stage")
    colometry: str = Field(..., description="Status of colometry normalization stage")
    features: str = Field(..., description="Status of feature extraction stage")


class GeometryResponse(BaseModel):
    """Response model for geometry normalization endpoint"""
    status: str = Field(..., description="Processing status: 'success' or 'error'")
    input_filename: Optional[str] = Field(None, description="Name of the uploaded input file")
    output_files: OutputFiles = Field(..., description="Paths to generated output files")
    metadata: Metadata = Field(..., description="Processing metadata and applied transformations")
    qa_flags: Dict[str, Any] = Field(..., description="Quality assurance flags indicating potential issues")
    temp_dirs: TempDirs = Field(..., description="Temporary directories used during processing")


class AnalyzeResponse(BaseModel):
    """Response model for full document analysis endpoint"""
    status: str = Field(..., description="Processing status: 'success' or 'error'")
    input_filename: Optional[str] = Field(None, description="Name of the uploaded input file")
    output_files: OutputFiles = Field(..., description="Paths to generated output files")
    metadata: Metadata = Field(..., description="Processing metadata and applied transformations")
    qa_flags: Dict[str, Any] = Field(..., description="Quality assurance flags indicating potential issues")
    pipeline_stages: PipelineStages = Field(..., description="Status of each pipeline stage")
    temp_dirs: TempDirs = Field(..., description="Temporary directories used during processing")
    classification: Optional[Dict[str, Any]] = Field(None, description="Document classification result (if enabled)")


class NotImplementedResponse(BaseModel):
    """Response model for not yet implemented endpoints"""
    status: str = Field(..., description="Status indicating the endpoint is not implemented")
    message: str = Field(..., description="Message explaining that the feature is not yet available")


class StatusResponse(BaseModel):
    """Response model for pipeline status endpoint"""
    status: str = Field(..., description="Overall pipeline status")
    stages: List[str] = Field(..., description="List of available pipeline stages")


class OCRLineResponse(BaseModel):
    """Response model for a single OCR line"""
    text: str = Field(..., description="Le texte reconnu de la ligne")
    confidence: float = Field(..., description="Le score de confiance de la reconnaissance")
    bounding_box: List[float] = Field(
        ..., 
        min_length=4,
        max_length=4,
        description="Boîte englobante au format rectangle [x_min, y_min, x_max, y_max]"
    )


class FeaturesResponse(BaseModel):
    """Response model for feature extraction endpoint"""
    status: str = Field(..., description="Statut du traitement")
    filename: Optional[str] = Field(None, description="Nom du fichier d'entrée")
    line_count: int = Field(..., description="Nombre de lignes de texte extraites")
    lines: List[OCRLineResponse] = Field(..., description="Liste des lignes de texte extraites")
    processing_time: float = Field(..., description="Temps de traitement en secondes")


class ClassificationResponse(BaseModel):
    """Response model for document classification endpoint"""
    status: str = Field(..., description="Statut du traitement")
    filename: Optional[str] = Field(None, description="Nom du fichier d'entrée")
    document_type: Optional[str] = Field(None, description="Type de document détecté")
    confidence: float = Field(..., description="Confiance de la classification (0.0-1.0)")
    processing_time: float = Field(..., description="Temps de traitement en secondes")


class PageClassificationResult(BaseModel):
    """Result for a single page classification"""
    page_number: int = Field(..., description="Numéro de page (1-indexed)")
    document_type: Optional[str] = Field(None, description="Type de document détecté")
    confidence: float = Field(..., description="Confiance de la classification (0.0-1.0)")


class MultiPageClassificationResponse(BaseModel):
    """Response model for multi-page document classification endpoint"""
    status: str = Field(..., description="Statut du traitement")
    filename: Optional[str] = Field(None, description="Nom du fichier d'entrée")
    total_pages: int = Field(..., description="Nombre total de pages traitées")
    results_by_page: List[PageClassificationResult] = Field(..., description="Résultats de classification par page")
    processing_time: float = Field(..., description="Temps de traitement en secondes")


class TaskResponse(BaseModel):
    """Response model for task creation"""
    task_id: str = Field(..., description="Unique task identifier")
    status: str = Field(..., description="Current task status")
    message: str = Field(..., description="Human-readable message")


class TaskStatusResponse(BaseModel):
    """Response model for task status query"""
    task_id: str = Field(..., description="Task identifier")
    status: str = Field(..., description="Current task status")
    created_at: Optional[str] = Field(None, description="Task creation timestamp")
    started_at: Optional[str] = Field(None, description="Task start timestamp")
    completed_at: Optional[str] = Field(None, description="Task completion timestamp")
    result: Optional[Dict[str, Any]] = Field(None, description="Task result (if completed)")
    error: Optional[str] = Field(None, description="Error message (if failed)")
    filename: Optional[str] = Field(None, description="Original filename")


# Helper function for background task execution
def execute_processing_task_sync(
    task_id: str,
    file_path: str,
    filename: str,
    temp_dirs: Dict[str, str],
    preprocessing_normalizer,
    geometry_normalizer,
    request_id: Optional[str] = None,
    is_full_analysis: bool = False
) -> None:
    """
    Execute processing task synchronously (to be run in background).
    
    Args:
        task_id: Task ID
        file_path: Path to input file
        filename: Original filename
        temp_dirs: Temporary directories
        preprocessing_normalizer: Preprocessing normalizer (injected)
        geometry_normalizer: Geometry normalizer (injected)
        request_id: Request ID for correlation (optional, will use context if not provided)
        is_full_analysis: Whether to run full analysis or just geometry
    """
    # Importer ici pour éviter les imports circulaires
    from src.utils.logger import set_request_id
    
    # Définir le request_id dans le contexte pour cette tâche
    if request_id:
        set_request_id(request_id)
    
    try:
        # Create service with injected dependencies
        service = ProcessingService(
            preprocessing_normalizer=preprocessing_normalizer,
            geometry_normalizer=geometry_normalizer
        )
        
        # Update task status to processing
        task_manager.update_task_status(task_id, TaskStatus.PROCESSING)
        logger.info(f"Début du traitement de la tâche {task_id}")
        
        # Run processing
        if is_full_analysis:
            result = service.process_full_analysis(
                file_path,
                filename,
                temp_dirs
            )
        else:
            result = service.process_geometry(
                file_path,
                filename,
                temp_dirs
            )
        
        # Update task with result
        task_manager.update_task_status(task_id, TaskStatus.COMPLETED, result=result)
        logger.info(f"Tâche {task_id} complétée avec succès")
        
        # Schedule cleanup after task completion
        # Note: In production, this should be handled by a proper task queue system
        cleanup_temp_files(temp_dirs)
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Erreur lors de l'exécution de la tâche {task_id}: {e}", exc_info=True)
        task_manager.update_task_status(task_id, TaskStatus.FAILED, error=error_msg)
        
        # Cleanup on error as well
        cleanup_temp_files(temp_dirs)


def cleanup_temp_files(temp_dirs: Dict[str, str]) -> None:
    """
    Clean up temporary files after response is sent.
    This function is designed to be called as a background task.
    
    Args:
        temp_dirs: Dictionary with temporary directory paths
    """
    # Create a temporary service instance for cleanup (no dependencies needed)
    service = ProcessingService()
    service.cleanup_temp_directories(temp_dirs)
    logger.info("Nettoyage des fichiers temporaires terminé")


@router.post(
    "/analyze",
    response_model=TaskResponse,
    status_code=202,
    summary="Complete Document Analysis (Async)",
    description="""
    Submits a document for complete analysis. Returns immediately with a task_id.
    Use GET /results/{task_id} to check the status and retrieve results.
    
    **Current Implementation:**
    - Preprocessing: Image enhancement, contrast improvement, and capture type classification (SCAN vs PHOTO)
    - Geometry Normalization: Intelligent cropping, deskew (angle correction), and orientation correction
    
    **Future Stages (Not Yet Implemented):**
    - Colometry Normalization: Column structure normalization
    - Feature Extraction: OCR text extraction and checkbox detection
    
    **Input:**
    - Accepts image files (PNG, JPG, JPEG, TIFF, BMP) or PDF files
    - Maximum file size depends on server configuration
    
    **Response:**
    - Returns 202 Accepted with a task_id
    - Processing happens asynchronously in the background
    - Use GET /results/{task_id} to check status and get results
    
    **Error Handling:**
    - Returns 400 for invalid file formats or empty files
    - Returns 500 for server errors
    """
)
async def analyze_document(
    background_tasks: BackgroundTasks,
    preprocessing_normalizer: Annotated[PreprocessingNormalizer, Depends(get_preprocessing_normalizer)],
    geometry_normalizer: Annotated[GeometryNormalizer, Depends(get_geometry_normalizer)],
    file: UploadFile = File(...)
) -> TaskResponse:
    """
    Submit document for complete analysis (asynchronous).
    """
    try:
        # Create service with injected dependencies
        service = ProcessingService(
            preprocessing_normalizer=preprocessing_normalizer,
            geometry_normalizer=geometry_normalizer
        )
        
        # 1. Validate file
        file_content = await file.read()
        file_extension, error = service.validate_file(file.filename, len(file_content))
        if error:
            raise HTTPException(status_code=400, detail=error)
        
        # 2. Create task
        task_id = task_manager.create_task(file.filename)
        
        # 3. Create temporary directories
        temp_dirs = service.create_temp_directories(prefix="analyze_")
        
        # 4. Save uploaded file
        temp_file_path = service.save_uploaded_file(
            file_content,
            file.filename or f"upload{file_extension}",
            temp_dirs['input']
        )
        
        # 5. Schedule background task for processing
        # Note: For production, consider using Celery or Dramatiq for better task management
        # Récupérer le request_id pour le propager à la tâche asynchrone
        current_request_id = get_request_id()
        background_tasks.add_task(
            execute_processing_task_sync,
            task_id=task_id,
            file_path=temp_file_path,
            filename=file.filename,
            temp_dirs=temp_dirs,
            preprocessing_normalizer=preprocessing_normalizer,
            geometry_normalizer=geometry_normalizer,
            request_id=current_request_id,
            is_full_analysis=True
        )
        
        # 6. Schedule cleanup after response is sent (with delay to allow task to complete)
        # Note: In production, cleanup should happen after task completion, not immediately
        # For now, we keep files until task is completed
        # background_tasks.add_task(cleanup_temp_files, temp_dirs)
        
        logger.info(f"Tâche d'analyse créée: {task_id} pour le fichier {file.filename}")
        
        return TaskResponse(
            task_id=task_id,
            status=TaskStatus.PENDING.value,
            message="Document analysis task created. Use GET /results/{task_id} to check status."
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur inattendue lors de la création de la tâche: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Erreur interne lors de la création de la tâche: {str(e)}"
        )


@router.post(
    "/pipeline/colometry",
    response_model=NotImplementedResponse,
    status_code=501,
    summary="Column Structure Normalization",
    description="""
    Normalizes the column structure of a document.
    
    **Status:** Not yet implemented
    
    **Planned Functionality:**
    This endpoint will normalize the column layout of documents, ensuring consistent column widths,
    detecting multi-column layouts, and standardizing column boundaries.
    
    **Future Parameters:**
    - Expected number of columns
    - Minimum column width thresholds
    - Column spacing normalization
    
    **Note:** This feature is planned for future implementation. Check the pipeline status endpoint
    for current implementation status.
    """
)
async def pipeline_colometry(file: UploadFile = File(...)) -> NotImplementedResponse:
    """
    Column structure normalization endpoint (not yet implemented).
    """
    return NotImplementedResponse(
        status="not_implemented",
        message="Column structure normalization - Not yet implemented"
    )


@router.post(
    "/pipeline/geometry",
    response_model=GeometryResponse,
    summary="Document Geometry Normalization",
    description="""
    Accepts an image or PDF file, applies preprocessing (enhancement, contrast improvement, classification)
    then performs geometry normalization (crop, deskew, rotation).
    
    Returns processing metadata and paths to generated files.
    
    **Processing Steps:**
    
    1. **Preprocessing:**
       - Image enhancement and contrast improvement
       - Capture type classification (SCAN vs PHOTO)
       - White level analysis to determine document type
    
    2. **Geometry Normalization:**
       - **Intelligent Cropping:** Automatically crops the document from background using doctr
       - **Deskew (Angle Correction):** Corrects document rotation/angle skew using Hough line detection
       - **Orientation Correction:** Detects and corrects document orientation (0°, 90°, 180°, 270°) using ONNX model
    
    3. **Quality Assurance:**
       - Generates QA flags for potential issues (low contrast, overcrop risk, small resolution, etc.)
       - Validates minimum quality standards
    
    **Input:**
    - Accepts image files (PNG, JPG, JPEG, TIFF, BMP) or PDF files
    - PDFs are converted to images at 300 DPI
    
    **Output:**
    - **transformed:** Path to the final processed image after all transformations
    - **original:** Path to the original image (if saved)
    - **transform_file:** JSON file containing all applied transformations
    - **qa_file:** JSON file containing quality assurance flags
    
    **Metadata Includes:**
    - Which transformations were applied (crop, deskew, rotation)
    - Detected orientation angle
    - Capture type (SCAN or PHOTO)
    - Processing time
    
    **Error Handling:**
    - Returns 400 for invalid file formats or empty files
    - Returns 500 for processing errors (preprocessing, geometry, model loading, etc.)
    """
)
async def pipeline_geometry(
    background_tasks: BackgroundTasks,
    preprocessing_normalizer: Annotated[PreprocessingNormalizer, Depends(get_preprocessing_normalizer)],
    geometry_normalizer: Annotated[GeometryNormalizer, Depends(get_geometry_normalizer)],
    file: UploadFile = File(...)
) -> GeometryResponse:
    """
    Process document geometry normalization (synchronous for backward compatibility).
    """
    # Create service with injected dependencies
    service = ProcessingService(
        preprocessing_normalizer=preprocessing_normalizer,
        geometry_normalizer=geometry_normalizer
    )
    
    temp_dirs = None
    
    try:
        # 1. Validate file
        file_content = await file.read()
        file_extension, error = service.validate_file(file.filename, len(file_content))
        if error:
            raise HTTPException(status_code=400, detail=error)
        
        # 2. Create temporary directories
        temp_dirs = service.create_temp_directories(prefix="geometry_")
        
        # 3. Save uploaded file
        temp_file_path = service.save_uploaded_file(
            file_content,
            file.filename or f"upload{file_extension}",
            temp_dirs['input']
        )
        
        # 4. Process document
        response_data = service.process_geometry(
            temp_file_path,
            file.filename,
            temp_dirs
        )
        
        # 5. Schedule cleanup after response is sent
        background_tasks.add_task(cleanup_temp_files, temp_dirs)
        
        return response_data
        
    except HTTPException:
        raise
    except (PreprocessingError, GeometryError, ModelLoadingError, ImageProcessingError) as e:
        logger.error(f"Erreur du pipeline: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors du traitement: {str(e)}"
        )
    except ValueError as e:
        logger.error(f"Erreur de validation: {e}", exc_info=True)
        raise HTTPException(status_code=400, detail=str(e))
    except PipelineError as e:
        logger.error(f"Erreur du pipeline: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Erreur du pipeline: {str(e)}"
        )
    except Exception as e:
        logger.error(f"Erreur inattendue lors du traitement géométrique: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Erreur interne lors du traitement: {str(e)}"
        )
    finally:
        # Cleanup is handled by background task, but ensure cleanup on error
        if temp_dirs:
            # Only cleanup on error, otherwise let background task handle it
            pass


def pdf_buffer_to_images(pdf_buffer: bytes, dpi: int = 300) -> List[np.ndarray]:
    """
    Convertit un PDF depuis un buffer mémoire en liste d'images numpy.
    
    Args:
        pdf_buffer: Contenu du PDF en bytes
        dpi: Résolution DPI pour la conversion
        
    Returns:
        List[np.ndarray]: Liste d'images numpy (une par page)
        
    Raises:
        HTTPException: Si la conversion échoue
    """
    try:
        import fitz  # PyMuPDF
    except ImportError:
        raise HTTPException(
            status_code=500,
            detail="PyMuPDF n'est pas installé. Installez-le avec: pip install PyMuPDF"
        )
    
    try:
        # Ouvrir le PDF depuis le buffer mémoire
        doc = fitz.open(stream=pdf_buffer, filetype="pdf")
        if len(doc) == 0:
            doc.close()
            raise HTTPException(status_code=400, detail="Le PDF est vide.")
        
        # Utiliser min_dpi depuis la config (défaut: 300 si non disponible)
        from src.utils.config_loader import get_config
        try:
            pdf_config = get_config().pdf
            min_dpi = pdf_config.min_dpi
        except:
            min_dpi = 300  # Fallback si la config n'est pas disponible
        actual_dpi = max(dpi, min_dpi)
        mat = fitz.Matrix(actual_dpi / 72, actual_dpi / 72)
        
        images = []
        # Boucler sur toutes les pages
        for page in doc:
            pix = page.get_pixmap(matrix=mat)
            
            # Convertir en numpy array
            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(
                pix.height, pix.width, pix.n
            )
            
            # Convertir le format de couleur selon le nombre de canaux
            if pix.n == 4:  # RGBA
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2BGR)
            elif pix.n == 3:  # RGB
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            elif pix.n == 1:  # Grayscale
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
            
            images.append(img_array)
        
        doc.close()
        return images
        
    except Exception as e:
        raise HTTPException(
            status_code=400,
            detail=f"Impossible de convertir le PDF en image: {str(e)}"
        )


@router.post(
    "/pipeline/features",
    response_model=FeaturesResponse,
    summary="Feature Extraction (OCR)",
    description="""
    Extrait le texte d'un document image ou PDF, ligne par ligne, en utilisant PaddleOCR.
    
    **Processus :**
    1. Valide et charge le fichier uploadé.
    2. Si c'est un PDF, convertit la première page en image.
    3. Appelle le moteur OCR pour extraire chaque ligne de texte.
    4. Retourne une liste structurée de lignes avec texte, confiance et coordonnées.
    
    Cette étape est optimisée pour la vitesse et sert de base pour la classification
    de documents et la localisation d'ancres.
    """
)
async def pipeline_features(
    feature_extractor: Annotated[FeatureExtractor, Depends(get_feature_extractor)],
    file: UploadFile = File(...)
) -> FeaturesResponse:
    """
    Extrait les features (OCR) d'un document.
    """
    start_time = time.time()
    
    try:
        # Lire le contenu du fichier
        file_content = await file.read()
        if not file_content:
            raise HTTPException(status_code=400, detail="Le fichier est vide.")
        
        # Convertir en image NumPy
        image_np: np.ndarray
        
        if is_pdf(file.filename or ""):
            # Utiliser PyMuPDF pour convertir le PDF en mémoire (première page seulement)
            images_np = pdf_buffer_to_images(file_content, dpi=300)
            image_np = images_np[0] if images_np else None
            if image_np is None:
                raise HTTPException(status_code=400, detail="Le PDF est vide.")
        else:
            # Convertir l'image directement depuis le buffer mémoire
            image_np = cv2.imdecode(np.frombuffer(file_content, np.uint8), cv2.IMREAD_COLOR)
            if image_np is None:
                raise HTTPException(status_code=400, detail="Format d'image invalide ou corrompu.")
        
        # Appeler notre FeatureExtractor
        extracted_lines = feature_extractor.extract_ocr(image_np)
        
        processing_time = time.time() - start_time
        
        # Convertir les dictionnaires en OCRLineResponse
        ocr_lines = [
            OCRLineResponse(**line) for line in extracted_lines
        ]
        
        return FeaturesResponse(
            status="success",
            filename=file.filename,
            line_count=len(ocr_lines),
            lines=ocr_lines,
            processing_time=processing_time
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de l'extraction de features : {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Erreur interne du serveur : {str(e)}"
        )


@router.post(
    "/classify",
    response_model=MultiPageClassificationResponse,
    summary="Document Type Classification",
    description="""
    Classifie le type de document depuis une image ou un PDF.
    
    **Processus :**
    1. Extrait les features OCR (via /pipeline/features)
    2. Vectorise le document avec des embeddings multi-modaux
    3. Classe le document avec le modèle ML entraîné
    4. Retourne le type de document et la confiance pour chaque page
    
    **Input:**
    - Accepts image files (PNG, JPG, JPEG, TIFF, BMP) or PDF files
    
    **Output:**
    - **total_pages:** Nombre total de pages traitées
    - **results_by_page:** Liste des résultats de classification pour chaque page
    - Pour chaque page: **document_type** (ex: "Attestation_CEE", "Facture") et **confidence** (0.0-1.0)
    - Si la confiance est en dessous du seuil configuré, document_type sera None
    
    **Note:** La classification doit être activée dans config.yaml (classification.enabled: true)
    """
)
async def classify_document(
    feature_extractor: Annotated[FeatureExtractor, Depends(get_feature_extractor)],
    document_classifier: Annotated[DocumentClassifier, Depends(get_document_classifier)],
    file: UploadFile = File(...)
) -> MultiPageClassificationResponse:
    """
    Classe le type de document depuis une image ou un PDF (toutes les pages).
    """
    start_time = time.time()
    
    try:
        # 1. Lire le contenu du fichier
        file_content = await file.read()
        if not file_content:
            raise HTTPException(status_code=400, detail="Le fichier est vide.")
        
        # 2. Convertir en images NumPy
        images_np: List[np.ndarray]
        
        if is_pdf(file.filename or ""):
            # Utiliser PyMuPDF pour convertir le PDF en mémoire (toutes les pages)
            images_np = pdf_buffer_to_images(file_content, dpi=300)
        else:
            # Pour une image simple, on la met dans une liste d'un seul élément
            img = cv2.imdecode(np.frombuffer(file_content, np.uint8), cv2.IMREAD_COLOR)
            if img is None:
                raise HTTPException(status_code=400, detail="Format d'image invalide ou corrompu.")
            images_np = [img]
        
        num_pages = len(images_np)
        page_results_list = [None] * num_pages
        
        # --- LOGIQUE DE PARALLÉLISATION ---
        # Seuil pragmatique : ne pas lancer de processus pour un petit nombre de pages
        # Le coût de création des processus peut être supérieur au gain.
        PARALLEL_PROCESSING_THRESHOLD = 2
        
        if num_pages >= PARALLEL_PROCESSING_THRESHOLD:
            logger.info(f"Traitement parallèle de {num_pages} pages...")
            # Préparer les tâches avec leur index original
            tasks = [(i, images_np[i]) for i in range(num_pages)]
            
            with ProcessPoolExecutor(max_workers=os.cpu_count(), initializer=init_api_worker) as executor:
                # `map` exécute la fonction sur chaque élément de `tasks` et préserve l'ordre
                results = executor.map(process_page_worker, tasks)
                
                for original_index, classification_result in results:
                    page_results_list[original_index] = PageClassificationResult(
                        page_number=original_index + 1,
                        document_type=classification_result.get('document_type'),
                        confidence=classification_result.get('confidence', 0.0)
                    )
        
        else:  # Traitement séquentiel pour les petits documents
            logger.info(f"Traitement séquentiel de {num_pages} page(s)...")
            for i, image_np in enumerate(images_np):
                ocr_lines = feature_extractor.extract_ocr(image_np)
                ocr_data = {'ocr_lines': ocr_lines}
                classification_result = document_classifier.predict(ocr_data)
                
                page_results_list[i] = PageClassificationResult(
                    page_number=i + 1,
                    document_type=classification_result.get('document_type'),
                    confidence=classification_result.get('confidence', 0.0)
                )
        
        processing_time = time.time() - start_time
        
        return MultiPageClassificationResponse(
            status="success",
            filename=file.filename,
            total_pages=num_pages,
            results_by_page=page_results_list,
            processing_time=processing_time
        )
        
    except HTTPException:
        raise
    except ValueError as e:
        # Erreur de configuration (classification non activée, modèle non trouvé, etc.)
        logger.error(f"Erreur de configuration pour la classification : {e}", exc_info=True)
        raise HTTPException(
            status_code=503,
            detail=f"Service de classification non disponible : {str(e)}"
        )
    except Exception as e:
        logger.error(f"Erreur lors de la classification : {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Erreur interne du serveur : {str(e)}"
        )


@router.get(
    "/results/{task_id}",
    response_model=TaskStatusResponse,
    summary="Get Task Status and Results",
    description="""
    Retrieve the status and results of an asynchronous processing task.
    
    **Use Cases:**
    - Check if a task is still processing
    - Retrieve results when task is completed
    - Get error information if task failed
    
    **Response Status:**
    - **pending:** Task created but not yet started
    - **processing:** Task is currently being processed
    - **completed:** Task completed successfully, results available
    - **failed:** Task failed, error message available
    
    **Response Fields:**
    - **task_id:** Unique task identifier
    - **status:** Current task status
    - **created_at:** When the task was created
    - **started_at:** When processing started (if started)
    - **completed_at:** When processing completed (if completed)
    - **result:** Complete processing results (if completed)
    - **error:** Error message (if failed)
    - **filename:** Original filename
    
    **Error Handling:**
    - Returns 404 if task_id is not found
    """
)
async def get_task_results(task_id: str) -> TaskStatusResponse:
    """
    Get the status and results of an asynchronous processing task.
    """
    task = task_manager.get_task(task_id)
    
    if not task:
        raise HTTPException(
            status_code=404,
            detail=f"Task {task_id} not found"
        )
    
    return TaskStatusResponse(**task.to_dict())


@router.get(
    "/pipeline/status",
    response_model=StatusResponse,
    summary="Pipeline Status",
    description="""
    Returns the current status of the document analysis pipeline.
    
    **Use Cases:**
    - Check which pipeline stages are available and implemented
    - Verify API health and readiness
    - Determine which endpoints are functional
    
    **Response:**
    - **status:** Overall pipeline status (e.g., "ready", "maintenance")
    - **stages:** List of available pipeline stages
    
    **Available Stages:**
    - **preprocessing:** Image enhancement and capture type classification (implemented)
    - **geometry:** Geometry normalization - crop, deskew, rotation (implemented)
    - **colometry:** Column structure normalization (not yet implemented)
    - **features:** Feature extraction - OCR and checkbox detection (not yet implemented)
    
    This endpoint does not require any input and can be used for health checks.
    """
)
async def pipeline_status() -> StatusResponse:
    """
    Returns the current status of the document analysis pipeline.
    """
    return StatusResponse(
        status="ready",
        stages=["preprocessing", "geometry", "colometry", "features"]
    )

